\section{Results}
After having described all the different implemented models, having formulated a hypothesis about which should be able to outperformed and explained how the models are trained and evaluated, it is now time to present and analyze the obtained results. This section will have four subsection. The first three will focus on each of the three capacity factors, analyzing separately which models outperform and why in each of them. The final section will be devoted to analyzing whether the custom loss function successfully outperforms the base loss function in extreme value modeling. 
\subsection{Solar PV}
\label{s:solar-pv-results}
The first results that will be presented are those of the photovoltaic solar capacity factor. The results will be presented for all metrics for all evaluated models in a similar way as was presented in \autoref{table:eval-metrics-test-validation-solar-th}: \nameref{table:eval-metrics-test-validation-solar-th}.

The metrics of the validation set obtained in the \nameref{s:model-training-and-validation} section will also be included as a reference point. 
\newpage
\begin{table}[ht]
    \footnotesize
    \begin{tabular}[l]{r|c|ccc|cc|}
        \toprule
        \textbf{Solar PV} &Benchmark&Regression&SARIMAX&VARMAX&SVM&XGBoost \\ 
        \midrule            
        Cramer von Mises&29.34&364.6&93.27&29.21&223.3&747.4 \\
        KL divergence&0.0002762&0.4844&0.1905&0.0002732&0.1662&1.586 \\
        ACF$_\xi$ distance&0.0127&0.1201&0.1089&0.01338&0.2289&0.1802 \\
        \midrule
        CCMD&0.01117&0.3291&0.1044&0.01117&0.8375&0.3549 \\
        CCF$_\xi^{Solar TH}$ distance&0.009855&0.1232&0.08045&0.009355&0.1484&0.3242 \\
        CCF$_\xi^{Wind}$ distance&0.01187&0.07759&0.04984&0.01203&0.1091&0.8558 \\
        \midrule
        CVaR$^+$ distance&-0.02966&8.394&0.08376&0.03057&0.6503&-0.7125 \\
        Tail dependence coefficient$^+$&0.3676&0.2671&0.3174&0.3676&0.1187&0.03397 \\
        Return level distance$^+$&0.01537&1.857e+07&-0.3411&-0.0004157&0.7803&-0.9312 \\
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[ht]
    \footnotesize
    \begin{flushright}
    \begin{tabular}[r]{|ccc|cccc}
        \toprule
        N-BEATS&N-HiTS&TimeMixer&TFT&Informer&FEDFormer&iTransformer  \\
        \midrule            
        69.43&47.81&52.58&2221&485.8&158.6&131.1 \\
        0.3452&0.003905&0.04968&2.721&1.302&0.5261&0.01814 \\
        0.1018&0.06985&0.04528&0.1769&0.2429&0.1729&0.05605 \\
        \midrule
        0.1959&0.4296&0.05632&0.5398&0.5675&0.5183&0.2093 \\
        0.0481&0.1829&0.0826&0.2603&0.1649&0.2608&0.0688 \\
        0.02316&0.01634&0.07532&0.4126&0.06594&0.1383&0.08443 \\
        \midrule
        1.037&0.003395&0.1888&-0.9442&-0.6828&-0.3569&0.1683 \\
        0.2831&0.3265&0.2032&0&0.04338&0.002283&0.3699 \\
        4.802&-0.1408&0.7089&-1.09&-0.02178&-0.3841&0.2181 \\
        \bottomrule
    \end{tabular}
    \end{flushright}
    \caption{Results of the different models for Solar PV\label{long}}
    \label{table:results-solar-pv}
\end{table}

Given the great number of metrics and the difficulty of easily interpreting them, here is another table with the rank of the model for each metric. That is, for each metric, each model will be shown as the 1st, 2nd, 3rd... best model. The benchmark has also been included in this ranking. In bold, the best model -- apart from the benchmark -- is highlighted. 
\newpage
\begin{table}[ht]
    \footnotesize
    \begin{tabular}[l]{r|c|ccc|cc|}
        \toprule
        \textbf{Solar PV} &Benchmark&Regression&SARIMAX&VARMAX&SVM&XGBoost \\
        \midrule            
        Cramer von Mises&(2)&(10)&(6)&\textbf{(1)}&(9)&(12) \\
        KL divergence&(2)&(9)&(7)&\textbf{(1)}&(6)&(12) \\
        ACF$_\xi$ distance&(1)&(8)&(7)&\textbf{(2)}&(12)&(11) \\
        \midrule
        CCMD&(2)&(7)&(4)&\textbf{(1)}&(13)&(8) \\
        CCF$_\xi^{Solar TH}$ distance&(2)&(7)&(5)&\textbf{(1)}&(8)&(13) \\
        CCF$_\xi^{Wind}$ distance&(1)&(8)&(5)&\textbf{(2)}&(10)&(13) \\
        \midrule
        CVaR$^+$ distance&(2)&(13)&(4)&(3)&(8)&(10) \\
        Tail dependence coefficient$^+$&(12)&(7)&(9)&(12)&(5)&(3) \\
        Return level distance$^+$&(2)&(13)&(6)&\textbf{(1)}&(9)&(10) \\
        \bottomrule
        Total&(26)&(82)&(53)&\textbf{(24)}&(80)&(92) \\
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[ht]
    \footnotesize
    \begin{flushright}
    \begin{tabular}[r]{|ccc|cccc}
        \toprule
        N-BEATS&N-HiTS&TimeMixer&TFT&Informer&FEDFormer&iTransformer \\
        \midrule            
        (5)&(3)&(4)&(13)&(11)&(8)&(7) \\
        (8)&(3)&(5)&(13)&(11)&(10)&(4) \\
        (6)&(5)&(3)&(10)&(13)&(9)&(4) \\
        \midrule
        (5)&(9)&(3)&(11)&(12)&(10)&(6) \\
        (3)&(10)&(6)&(11)&(9)&(12)&(4) \\
        (4)&(3)&(7)&(12)&(6)&(11)&(9) \\
        \midrule
        (12)&\textbf{(1)}&(6)&(11)&(9)&(7)&(5) \\
        (8)&(10)&(6)&\textbf{(1)}&(4)&(2)&(13) \\
        (12)&(4)&(8)&(11)&(3)&(7)&(5) \\
        \bottomrule
        (63)&(48)&(48)&(93)&(78)&(76)&(57) \\
        \bottomrule
    \end{tabular}
    \end{flushright}
    \caption{Results of the rank of the different models for Solar PV\label{long}}
    \label{table:results-rank-solar-pv}
\end{table}

At the bottom of \autoref{table:results-rank-solar-pv} a Total can be found. This total is the sum of the rank of the model accross all metrics and it can be seen as a very simple proxy of the overall goodness of the model across all domains -- distribution fit, multivariate coherence and extreme value fit. 

When first seeing these results many insights can be extracted. The first one is about the evaluation metrics themselves. By looking at \autoref{table:results-rank-solar-pv} one can see that the rank of a given model for the evaluation metrics in a given category -- distribution fit, multivariate coherence and extreme value fit -- are generally congruent with each other. That is, if one of the models is one of the best according to the Cramer von Mises metric for example, it will tend to be ranked highly also with the KL divergence and ACF$_\xi$ distance metrics. However, that is not the case for the Tail dependence coefficient$^+$. This metric can be more affected by shifts in extreme value presence than the other two, and thus it can be seen how it contains more noise than the others and does not reflect the same ranking among models. That is why, this metric will not be as highly taken into account as the other two extreme value metrics. However, it will still be included for completeness sake. 

The most relevant and straightforward insight that can be obtained is which is the best overall model of them all. In the case of solar PV the answer is very clear, it is -- maybe surprisingly -- the VARMAX model. It could be considered that the series modeled by the solar PV is practically as realistic as the empirical data, being practically always at the same level as the benchmark, even surpassing it in many metrics. This could be surprising given the apparent simplicity of the VARMAX model. It is strictly linear, with no inherent way of capturing complex or long term dependencies. The only part where the good performance shouldn't come as a surprise is in the metrics regarding the relationship of the predicted series with the other two variables, given how the inherently multivariate nature of the VARMAX could be an advantage to other models that use the strictly univariate or univariate with exogenous variables type. 

The next best models both belong to the NN category, being the N-HiTS and the TimeMixer models. As it could be expected, the TimeMixer model is slightly better in the multivariate relationships category, while the N-HiTS is slightly better in the general distribution -- although marginally -- and in the extreme value prediction -- if the Tail dependence coefficient is ignored, given the reasoning explained above. 

Perhaps the most surprising observation is the bad general performance of the transformer based models. All of them except for the iTransformer are among the worst performers, remainig at the level of or slightly above or below the most naive model, the plain regression. This could be attributed to the complexity of the models, which could have led them to overfitting. The good performance of the iTransformer with respect to the other architectures is consistent with the benchmarks performed by \cite{wang2024tssurvey}, however its worse performance compared to the VARMAX and its lack of improvement compared to the NN based models is quite disappointing. 

Finally, regarding the machine learning methods the conclusions are similar to those of the transformer based models. Their performance is among the worst of all the models. They seem to have joined the worst characteristics of the simple statistical methods and the more complex NN based methods. The way of encoding seasonal and time varying data is not as sophisticated as for the NN models as they only use the Fourier decompositions, however by adding extra complexity in the way those decompositions are used compared to the statistical methods they seem to overfit and end up performing even worse than these simpler models. Among themselves, it seems like the SVM is better equiped than the XGBoost to model the general distribution of the data, with less conclusive results in the other two categories.  

\subsection{Solar TH}
For the solar thermal capacity factor series, the results will be shown in the same way as for the \nameref{s:solar-pv-results} section. The two tables showing the metrics' values and the rank of the models will be presented, and they will later be discussed. 

% Given the similarity of this series to the previous one, similar results are expected, maybe with better performance of the 

% \newpage
\begin{table}[ht]
    \footnotesize
    \begin{tabular}[l]{r|c|ccc|cc|}
        \toprule
        \textbf{Solar TH} &Benchmark&Regression&SARIMAX&VARMAX&SVM&XGBoost \\ 
        \midrule            
        Cramer von Mises&12.87&239.5&144.6&14.59&93.37&653.9 \\
        KL divergence&0.01016&0.2558&0.1379&0.01094&0.4101&4.31 \\
        ACF$_\xi$ distance&0.02488&0.2246&0.1936&0.02532&0.1988&0.2507 \\
        \midrule
        CCMD&0.01117&0.3291&0.1044&0.01117&0.8375&0.3549 \\
        CCF$_\xi^{Solar PV}$ distance&0.01513&0.1008&0.08724&0.01545&0.1686&0.2552 \\
        CCF$_\xi^{Wind}$ distance&0.02013&0.08723&0.1107&0.01912&0.1124&0.861 \\
        \midrule
        CVaR$^+$ distance&0.0732&2.869&-0.04785&-0.06821&11.09&-0.8908 \\
        Tail dependence coefficient$^+$&0.3356&0.3676&0.3539&0.3356&0.05479&0.08844 \\
        Return level distance$^+$&0.2928&17.04&-1.004&-0.1932&1.394e+10&-0.8234 \\
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[ht]
    \footnotesize
    \begin{flushright}
    \begin{tabular}[r]{|ccc|cccc}
        \toprule
        N-BEATS&N-HiTS&TimeMixer&TFT&Informer&FEDFormer&iTransformer  \\
        \midrule            
        134&124.2&251.4&699.1&714.9&495.9&26.38 \\
        0.2427&0.05258&0.9605&0.4706&0.8153&1.35&0.04629 \\
        0.1812&0.5174&0.1061&0.1951&0.4585&0.1844&0.1639 \\
        \midrule
        0.1959&0.4296&0.05632&0.5398&0.5675&0.5183&0.2093 \\
        0.03605&0.1889&0.09468&0.168&0.2716&0.2363&0.07058 \\
        0.118&0.6707&0.07896&0.208&0.5203&0.1325&0.1419 \\
        \midrule
        1.818&-0.1942&-0.6187&5.324&-0.1614&-0.7453&-0.1516 \\
        0.3813&0.05251&0.2192&0&0.09589&0.08904&0.3721 \\
        6.143&-1.018&-0.8051&0.8068&0.0144&-0.8311&-0.3048 \\
        \bottomrule
    \end{tabular}
    \end{flushright}
    \caption{Results of the different models for Solar TH\label{long}}
    \label{table:results-solar-th}
\end{table}
Again, the model rank table will be shown to better interpret these results.

\newpage
\begin{table}[ht]
    \footnotesize
    \begin{tabular}[l]{r|c|ccc|cc|}
        \toprule
        \textbf{Solar TH} &Benchmark&Regression&SARIMAX&VARMAX&SVM&XGBoost \\
        \midrule            
        Cramer von Mises&(1)&(8)&(7)&\textbf{(2)}&(4)&(11) \\
        KL divergence&(1)&(7)&(5)&\textbf{(2)}&(8)&(13) \\
        ACF$_\xi$ distance&(1)&(10)&(7)&\textbf{(2)}&(9)&(11) \\
        \midrule
        CCMD&(2)&(7)&(4)&\textbf{(1)}&(13)&(8) \\
        CCF$_\xi^{Solar PV}$ distance&(1)&(7)&(5)&\textbf{(2)}&(9)&(12) \\
        CCF$_\xi^{Wind}$ distance&(2)&(4)&(5)&\textbf{(1)}&(6)&(13) \\
        \midrule
        CVaR$^+$ distance&(3)&(11)&\textbf{(1)}&(2)&(13)&(9) \\
        Tail dependence coefficient$^+$&(8)&(11)&(10)&(8)&(3)&(4) \\
        Return level distance$^+$&(3)&(12)&(9)&(2)&(13)&(7) \\
        \bottomrule
        Total&(22)&(77)&(53)&\textbf{(22)}&(78)&(88) \\
\bottomrule
    \end{tabular}
\end{table}
\begin{table}[ht]
    \footnotesize
    \begin{flushright}
    \begin{tabular}[r]{|ccc|cccc}
        \toprule
        N-BEATS&N-HiTS&TimeMixer&TFT&Informer&FEDFormer&iTransformer \\
        \midrule            
        (6)&(5)&(9)&(12)&(13)&(10)&(3) \\
        (6)&(4)&(11)&(9)&(10)&(12)&(3) \\
        (5)&(13)&(3)&(8)&(12)&(6)&(4) \\
        \midrule
        (5)&(9)&(3)&(11)&(12)&(10)&(6) \\
        (3)&(10)&(6)&(8)&(13)&(11)&(4) \\
        (7)&(12)&(3)&(10)&(11)&(8)&(9) \\
        \midrule
        (10)&(6)&(7)&(12)&(5)&(8)&(4) \\
        (13)&(2)&(7)&\textbf{(1)}&(6)&(5)&(12) \\
        (11)&(10)&(5)&(6)&\textbf{(1)}&(8)&(4) \\
        \bottomrule
        (66)&(71)&(54)&(77)&(83)&(78)&(49) \\
        \bottomrule
    \end{tabular}
    \end{flushright}
    \caption{Results of the rank of the different models for Solar TH\label{long}}
    \label{table:results-rank-solar-pv}
\end{table}

The first thing that should be taken into account before analyzing these results is that the solar thermal series is very similar to the solar photovoltaic series, therefore similar results should be expected. The only difference being more variability at night and higher dependence on previous values of the cross series, mainly of solar photovoltaic. However, the results should still be quite similar.

Perhaps because of this it is now less surprising to see again the VARMAX as the undisputed best model. It is again the best model in all categories. 

The general performance of all model types is slightly different in this case. Even though the statistical methods -- appart from the plain regression -- are still the best overall methods, less difference is seen with the best models of the NN architectures -- the TimeMixer -- and the transformer architecutres -- the iTransformer. The gap between these models and the rest of the models of their type is widened, very probably due to these two models being the only ones that are inherently multivariate of them all. In fact, the top three models are all inherently multivariate. This is most probably due to the fact that the solar thermal series has a high correlation with lagged solar photovoltaic and wind values. Therefore, models capable of better modeling these relationships should be better at both modeling the overall distribution of the variable and its relationship with the other two distributions. 

In the case of the solar thermal another thing that was also visible in the solar photovoltaic returns is confirmed here. The transformer based models are comparatively better in the extreme value modeling than in the other two categories. This is probably due to the extreme values being determined by more complex or long run patterns, where the transformer models are better equiped to deal with them than the machine learning or NN models. 

\subsection{Wind}
The last of the three series is the most different compared to the other two, given the much lower seasonality in wind production and its higher degree of dependence on past cross series. The results obtained for the wind series are the following. Note how in this case both the positive and negative extreme values hold some interest as the lower end of the distribution is no longer zero. In fact, moments of very low wind generation are of special interest given these are the moments when the rest of the energy sources would have to step up.  

\newpage
\begin{table}[ht]
    \footnotesize
    \begin{tabular}[l]{r|c|ccc|cc|}
        \toprule
        \textbf{Wind} &Benchmark&Regression&SARIMAX&VARMAX&SVM&XGBoost \\ 
        \midrule            
        Cramer von Mises&9.483&1783&1814&9.483&434.2&774.6 \\
        KL divergence&0.001479&1.109&1.208&0.001505&0.1318&0.3214 \\
        ACF$_\xi$ distance&0.06016&0.3458&0.3143&0.06525&0.3302&0.6625 \\
        \midrule
        CCMD&0.01117&0.3291&0.1044&0.01117&0.8375&0.3549 \\
        CCF$_\xi^{Solar PV}$ distance&0.01282&0.1621&0.1686&0.01252&0.115&0.4045 \\
        CCF$_\xi^{Solar TH}$ distance&0.01363&0.242&0.2763&0.01133&0.0808&0.525 \\
        \midrule
        CVaR$^+$ distance&-0.02357&0.4225&0.06328&0.02414&0.02966&-0.5748 \\
        CVaR$^-$ distance&-0.2462&5.582&6.485&0.3266&2.912&5.746 \\
        Tail dependence coefficient$^+$&0.04795&0.09132&0.1256&0.04795&0.1119&0.05028 \\
        Tail dependence coefficient$^-$&0.1507&0.1027&0.1553&0.1507&0.05023&0.05003 \\
        Return level distance$^+$&1.362&-0.4957&-0.4707&-0.5767&-0.5813&-1.081 \\
        Return level distance$^-$&-13.51&-7.643&-8.188&-1.139&-3.629&-5.709 \\
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[ht]
    \footnotesize
    \begin{flushright}
    \begin{tabular}[r]{|ccc|cccc}
        \toprule
        N-BEATS&N-HiTS&TimeMixer&TFT&Informer&FEDFormer&iTransformer  \\
        \midrule            
        381.2&504&553.8&729.6&1283&236&309.9 \\
        0.4356&0.2818&0.2442&0.3298&0.6615&0.1116&0.1838 \\
        0.2918&0.4957&0.2992&0.3452&0.5537&0.3348&0.3312 \\
        \midrule
        0.1959&0.4296&0.05632&0.5398&0.5675&0.5183&0.2093 \\
        0.03014&0.03572&0.04976&0.3294&0.4744&0.03619&0.1731 \\
        0.1954&0.7625&0.06438&0.4002&0.7358&0.03586&0.2802 \\
        \midrule
        -0.5646&-0.504&-0.3975&-0.5549&-0.1147&0.5273&-0.395 \\
        2.788&4.813&3.941&5.036&4.858&0.7204&3.297 \\
        0.09132&0.105&0.08904&0.05479&0.02727&0.02968&0.07534 \\
        0.1119&0.1005&0.09589&0.05251&0.1005&0.04795&0.1872 \\
        -0.8006&-0.9889&-0.8401&-0.9307&-0.4494&0.7511&-0.786 \\
        -2.105&-1.986&-5.443&-6.162&-6.413&-0.6112&-1.679 \\
        \bottomrule
    \end{tabular}
    \end{flushright}
    \caption{Results of the different models for Wind\label{long}}
    \label{table:results-wind}
\end{table}

The rank of each of the models can be seen in \autoref{table:results-rank-wind}. Note how in this case, since both the upper and lower extreme metrics are evaluated, the weight of the extreme value metrics in the total rank will be higher and can skew the percieved overall performance of the models when using this metric.

\newpage
\begin{table}[ht]
    \footnotesize
    \begin{tabular}[l]{r|c|ccc|cc|}
        \toprule
        \textbf{Wind} &Benchmark&Regression&SARIMAX&VARMAX&SVM&XGBoost \\
        \midrule            
        Cramer von Mises&(2)&(12)&(13)&\textbf{(2)}&(6)&(10) \\
        KL divergence&(1)&(12)&(13)&\textbf{(2)}&(4)&(8) \\
        ACF$_\xi$ distance&(1)&(10)&(5)&\textbf{(2)}&(6)&(13) \\
        \midrule
        CCMD&(2)&(7)&(4)&\textbf{(1)}&(13)&(8) \\
        CCF$_\xi^{Solar PV}$ distance&(2)&(8)&(9)&\textbf{(1)}&(7)&(12) \\
        CCF$_\xi^{Solar TH}$ distance&(2)&(7)&(8)&\textbf{(1)}&(5)&(11) \\
        \midrule
        CVaR$^+$ distance&(1)&(8)&(4)&\textbf{(2)}&(3)&(13) \\
        CVaR$^-$ distance&(1)&(11)&(13)&\textbf{(2)}&(5)&(12) \\
        Tail dependence coefficient$^+$&(4)&(10)&(13)&(4)&(12)&(5) \\
        Tail dependence coefficient$^-$&(10)&(8)&(12)&(10)&(3)&(2) \\
        Return level distance$^+$&(13)&(3)&(2)&(4)&(5)&(12) \\
        Return level distance$^-$&(13)&(11)&(12)&(2)&(6)&(8) \\
        \bottomrule
        Total&(52)&(106)&(108)&\textbf{(32)}&(75)&(114) \\
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[ht]
    \footnotesize
    \begin{flushright}
    \begin{tabular}[r]{|ccc|cccc}
        \toprule
        N-BEATS&N-HiTS&TimeMixer&TFT&Informer&FEDFormer&iTransformer \\
        \midrule            
        (5)&(7)&(8)&(9)&(11)&(3)&(4) \\
        (10)&(7)&(6)&(9)&(11)&(3)&(5) \\
        (3)&(11)&(4)&(9)&(12)&(8)&(7) \\
        \midrule
        (5)&(9)&(3)&(11)&(12)&(10)&(6) \\
        (3)&(4)&(6)&(11)&(13)&(5)&(10) \\
        (6)&(13)&(4)&(10)&(12)&(3)&(9) \\
        \midrule
        (12)&(9)&(7)&(11)&(5)&(10)&(6) \\
        (4)&(8)&(7)&(10)&(9)&(3)&(6) \\
        (10)&(11)&(8)&(6)&\textbf{(1)}&(2)&(7) \\
        (9)&(6)&(5)&(4)&(6)&\textbf{(1)}&(13) \\
        (8)&(11)&(9)&(10)&\textbf{(1)}&(6)&(7) \\
        (5)&(4)&(7)&(9)&(10)&\textbf{(1)}&(3) \\
        \bottomrule
        (80)&(100)&(74)&(109)&(104)&(55)&(83) \\
        \bottomrule
    \end{tabular}
    \end{flushright}
    \caption{Results of the rank of the different models for Wind\label{long}}
    \label{table:results-rank-wind}
\end{table}

Surprisingly, the results in this last series are very similar to those in the previous two. The best performing model overall is again the VARMAX model, performing at the benchmark level. This model manages to be the best in general distribution fit and in multivariate coherence, and to be among the best in extreme value modeling. 

Regarding extreme value modeling, again the transformer based models are the ones that excel at this -- in contrast with the other characteristics. This is probably due to the extreme values in the wind series being caused by more complex patterns where transformer models actually have an edge. Interestingly, this series is the first where the best performing model is not the iTransformer but the FEDFormer, which actually becomes the second best performing model after the VARMAX and with quite a big advantage over the rest of the transformer models. It seems like the frequency decomposition performed by this model and headed into the attention mechanism actually helps in modeling the wind series, which appears to be more driven by frequency characteristics than any other thing. 

The machine learning models again perform quite poorly, although here the advantage of the SVM method over the XGBoost that could be seen in the other two sets of results is even more accentuated. This is probably due to a higher presence of outliers in the wind series, with the SVM model being more robust to the presence of outliers than the XGBoost model. 

Regarding the NN models, the TimeMixer is again the best performing one. However, interestingly the N-HiTS seems to have lost its edge over the N-BEATS model. This is unexpected given the previous hypothesis where the wind series was driven mainly by frequency based mechanisms, as the N-HiTS should be better equiped than the N-BEATS to capture this behaviour. 
\subsection{Custom loss function}
After having analyzed the results for all models in the three capacity factor series, it is now time to analyze the results regarding the hypothesis of the custom loss function. That is, can the behaviour of the model be steered through a custom loss function -- in this case the SERA loss -- to better predict extreme values? As explained in the \nameref{s:loss-function} section, an XGBoost model has been trained using this loss function with the same hyperparameters as the base XGBoost model. In fact, two such models have been implemented, one focusing on the upper tail extreme values and one focusing on the lower tail extreme values. The relevance function in both cases has been to give a relevance of 1 to the top or bottom 10\%, a relevance of 0 to the opposite 10\% and the rest of the distribution is given a relevance based on the spline interpolation. 

Note that the modeling has been done using the custom loss only for the wind modeling, given this is the series where there is a highest practical interest to accurately predict extreme events. The results are as follows. 

\newpage
\begin{table}[ht]
    \centering
    \footnotesize
    \begin{tabular}[r]{r|c|cc}
        \toprule
        &XGBoost&XGBoost$^-$&XGBoost$^+$ \\
        \midrule            
        Cramer von Mises&774.6&1332&1978 \\
        KL divergence&0.3214&0.6029&1.678 \\
        ACF$_\xi$ distance&0.6625&0.6622&0.2574 \\
        \midrule
        CCMD&0.3549&0.3584&0.4519 \\
        CCF$_\xi^{Solar PV}$ distance&0.4045&0.3901&0.3306 \\
        CCF$_\xi^{Solar TH}$ distance&0.525&0.5031&0.4071 \\
        \midrule
        CVaR$^+$ distance&-0.5748&-0.4043&-0.235 \\
        CVaR$^-$ distance&5.746&8.46&11.03 \\
        Tail dependence coefficient$^+$&0.05028&0.05008&0.05974 \\
        Tail dependence coefficient$^-$&0.05003&0.04982&0.01963 \\
        Return level distance$^+$&-1.081&-1.206&-0.81 \\
        Return level distance$^-$&-5.709&-6.974&-8.092 \\
        \bottomrule
    \end{tabular}
    \caption{Results of the XGBoost models with SERA loss functions for Wind\label{long}}
    \label{table:results-custom-loss}
\end{table}

Even though these results are much easier to read and interpret than the ones where all of the models are included, the rank will still be provided in order to help interpret the results as much as possible. 

\begin{table}[ht]
    \centering
    \footnotesize
    \begin{tabular}[r]{r|c|cc}
        \toprule
        &XGBoost&XGBoost$^-$&XGBoost$^+$ \\
        \midrule            
        Cramer von Mises&\textbf{(1)}&(2)&(3) \\
        KL divergence&\textbf{(1)}&(2)&(3) \\
        ACF$_\xi$ distance&(3)&(2)&\textbf{(1)} \\
        \midrule
        CCMD&\textbf{(1)}&(2)&(3) \\
        CCF$_\xi^{Solar PV}$ distance&(3)&(2)&\textbf{(1)} \\
        CCF$_\xi^{Solar TH}$ distance&(3)&(2)&\textbf{(1)} \\
        \midrule
        CVaR$^+$ distance&(3)&(2)&\textbf{(1)} \\
        CVaR$^-$ distance&\textbf{(1)}&(2)&(3) \\
        Tail dependence coefficient$^+$&(2)&\textbf{(1)}&(3) \\
        Tail dependence coefficient$^-$&(3)&(2)&\textbf{(1)} \\
        Return level distance$^+$&(2)&(3)&\textbf{(1)} \\
        Return level distance$^-$&\textbf{(1)}&(2)&(3) \\
        \bottomrule
    \end{tabular}
    \caption{Results of the XGBoost models' rank with SERA loss functions for Wind\label{long}}
    \label{table:results-custom-loss}
\end{table}

The first insight that can be obtained from these results is that, unsurprisingly, the unbiased XGBoost model seems to be the one best representing the general distribution of the series. This is to be expected as the other two models will probably have introduced some bias in order to better fit extreme values. However, what is surprising is how the upper tail focused model performs better in the ACF$_\xi$ distance metric. That is, this model better showcases the temporal relation of the wind series with itself than any of the other two. 

Interestingly, this holds not only for the self temporal correlation but also for the cross temporal correlation, with this model being the also the best one regarding the correlation of the wind values with lagged values of the other two series. 

Regarding extreme values, which is actually the whole purpose of introducing the custom loss function, a couple interesting observations can be made. The first one is to reiterate the low value of the Tail dependence coefficient metric, as it shows results which are completely opposite to the other two and completely unintuitive, showing the models to be best in the opposite tail to the one they should be focusing on. Regarding the other two metrics, the results are much more fitting to expectations. Introducing the SERA loss seems to correctly steer the model into correctly modeling the upper tail of the wind capacity factor. However, this result cannot be replicated for the lower tail and the unbiased model is actually the one with the best performance in the lower extreme values. 